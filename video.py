import streamlit as st
import asyncio
import edge_tts
from moviepy.editor import *
import tempfile
import os

# ================= é…ç½®åŒºåŸŸ =================
# è¿™é‡Œå¡«ä½ ä¸Šä¼ åˆ° GitHub çš„å­—ä½“æ–‡ä»¶å
# å¦‚æœä½ ä¼ çš„æ˜¯ font.ttf å°±å¡« "font.ttf"
# å¦‚æœä½ ä¼ çš„æ˜¯ msyh.ttc å°±å¡« "msyh.ttc"
DEFAULT_FONT = "font.ttf" 

# ================= é¡µé¢è®¾ç½® =================
st.set_page_config(page_title="å•è¯è§†é¢‘ç”Ÿæˆå™¨", layout="wide")
st.title("ğŸ¬ æ¯æ—¥å•è¯è§†é¢‘ç”Ÿæˆå™¨ (è‡ªåŠ¨åŠ è½½å­—ä½“ç‰ˆ)")

# ================== ä¾§è¾¹æ ï¼šç´ æé…ç½® ==================
st.sidebar.header("âš™ï¸ ç´ æé…ç½®")

# æ£€æŸ¥å­—ä½“æ˜¯å¦å­˜åœ¨
if not os.path.exists(DEFAULT_FONT):
    st.sidebar.error(f"âš ï¸ è­¦å‘Šï¼šæœªåœ¨ä»“åº“ä¸­æ‰¾åˆ° {DEFAULT_FONT}ï¼è¯·å» GitHub ä¸Šä¼ å­—ä½“æ–‡ä»¶ã€‚")
    current_font = "Arial" # é™çº§å¤„ç†
else:
    st.sidebar.success(f"âœ… å·²è‡ªåŠ¨åŠ è½½å­—ä½“: {DEFAULT_FONT}")
    current_font = DEFAULT_FONT

# èƒŒæ™¯å›¾è¿˜æ˜¯å»ºè®®ä¿ç•™ä¸Šä¼ åŠŸèƒ½ï¼Œå› ä¸ºæ¯å¤©å¯èƒ½æƒ³æ¢ä¸ä¸€æ ·çš„å›¾
# ä½†å¦‚æœä½ æƒ³å›ºå®šä¸€å¼ å›¾ï¼Œä¹Ÿå¯ä»¥åƒå­—ä½“ä¸€æ ·å¤„ç†
bg_file = st.sidebar.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ (9:16ç«–å±, ä¸ä¼ åˆ™ç”¨é»‘åº•)", type=["jpg", "png", "jpeg"])
tick_file = st.sidebar.file_uploader("ä¸Šä¼ å€’è®¡æ—¶éŸ³æ•ˆ (å¯é€‰)", type=["mp3", "wav"])

# ================== ä¸»ç•Œé¢ï¼šå†…å®¹è¾“å…¥ ==================
st.divider()
col1, col2 = st.columns(2)

with col1:
    word = st.text_input("å•è¯ (Word)", value="Ambition")
    ipa = st.text_input("éŸ³æ ‡ (IPA)", value="/Ã¦mËˆbÉªÊƒn/")
    meaning = st.text_input("ä¸­æ–‡é‡Šä¹‰", value="n. é‡å¿ƒï¼›é›„å¿ƒï¼›æŠ±è´Ÿ")

with col2:
    sentence = st.text_area("è‹±æ–‡ä¾‹å¥", value="Her ambition was to become a pilot.")
    translation = st.text_input("ä¾‹å¥ç¿»è¯‘", value="å¥¹çš„æŠ±è´Ÿæ˜¯æˆä¸ºä¸€åé£è¡Œå‘˜ã€‚")

# ================== æ ¸å¿ƒé€»è¾‘å‡½æ•° ==================

async def generate_tts(text, voice, output_file):
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_file)

def process_video(bg_path, font_path, tick_path, data):
    temp_dir = tempfile.mkdtemp()
    audio_word_path = os.path.join(temp_dir, "word.mp3")
    audio_full_path = os.path.join(temp_dir, "full.mp3")
    output_video_path = os.path.join(temp_dir, "output.mp4")

    # 1. ç”Ÿæˆè¯­éŸ³
    asyncio.run(generate_tts(data['word'], "en-US-ChristopherNeural", audio_word_path))
    full_text = f"{data['word']}... {data['meaning']}... {data['sentence']}"
    asyncio.run(generate_tts(full_text, "zh-CN-YunxiNeural", audio_full_path))

    # 2. è½½å…¥ç´ æ
    if bg_path:
        bg_clip = ImageClip(bg_path).resize((1080, 1920))
    else:
        bg_clip = ColorClip(size=(1080, 1920), color=(0,0,0))

    audio_word_clip = AudioFileClip(audio_word_path)
    audio_full_clip = AudioFileClip(audio_full_path)
    
    tick_sfx = None
    if tick_path:
        try:
            tick_sfx = AudioFileClip(tick_path).subclip(0, 3).volumex(0.3)
        except:
            pass

    # --- é˜¶æ®µ 1 ---
    phase1_duration = max(3.5, audio_word_clip.duration + 2.5)
    
    txt_word_huge = TextClip(data['word'], fontsize=150, color='white', font=font_path, method='label')
    txt_word_huge = txt_word_huge.set_position('center').set_duration(phase1_duration)
    
    audio_track_1 = audio_word_clip
    if tick_sfx:
        audio_track_1 = CompositeAudioClip([audio_word_clip, tick_sfx.set_start(0.5)])
    
    clip_phase_1 = CompositeVideoClip([bg_clip.set_duration(phase1_duration), txt_word_huge])
    clip_phase_1 = clip_phase_1.set_audio(audio_track_1.set_duration(phase1_duration))

    # --- é˜¶æ®µ 2 ---
    phase2_duration = audio_full_clip.duration + 1.0
    
    txt_word_top = TextClip(data['word'] + "\n" + data['ipa'], fontsize=100, color='yellow', font=font_path, method='label')
    txt_word_top = txt_word_top.set_position(('center', 400)).set_duration(phase2_duration)
    
    txt_meaning = TextClip(data['meaning'], fontsize=70, color='white', font=font_path, method='caption', size=(900, None))
    txt_meaning = txt_meaning.set_position(('center', 'center')).set_duration(phase2_duration)
    
    ex_text = f"{data['sentence']}\n{data['translation']}"
    txt_example = TextClip(ex_text, fontsize=50, color='lightgrey', font=font_path, method='caption', size=(900, None))
    txt_example = txt_example.set_position(('center', 1300)).set_duration(phase2_duration)

    clip_phase_2 = CompositeVideoClip([
        bg_clip.set_duration(phase2_duration),
        txt_word_top,
        txt_meaning,
        txt_example
    ])
    clip_phase_2 = clip_phase_2.set_audio(audio_full_clip)

    final_video = concatenate_videoclips([clip_phase_1, clip_phase_2])
    final_video.write_videofile(output_video_path, fps=24, codec='libx264', audio_codec='aac')
    return output_video_path

# ================== æ‰§è¡Œ ==================
if st.button("ğŸš€ ç”Ÿæˆè§†é¢‘", type="primary"):
    with st.spinner("æ­£åœ¨åˆæˆ..."):
        try:
            # å¤„ç†èƒŒæ™¯å›¾
            t_bg = None
            if bg_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as f:
                    f.write(bg_file.read())
                    t_bg = f.name
            
            # å¤„ç†éŸ³æ•ˆ
            t_tick = None
            if tick_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                    f.write(tick_file.read())
                    t_tick = f.name

            data = {"word": word, "ipa": ipa, "meaning": meaning, "sentence": sentence, "translation": translation}
            
            # ç›´æ¥ä¼ å…¥ current_font (è¿™æ˜¯æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²)
            video_path = process_video(t_bg, current_font, t_tick, data)
            
            st.success("âœ… å®Œæˆï¼")
            st.video(video_path)
            with open(video_path, "rb") as file:
                st.download_button("â¬‡ï¸ ä¸‹è½½è§†é¢‘", data=file, file_name=f"{word}_video.mp4", mime="video/mp4")
                
        except Exception as e:
            st.error(f"å‡ºé”™: {e}")

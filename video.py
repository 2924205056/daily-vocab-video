import streamlit as st
import asyncio
import edge_tts
from moviepy.editor import *
import tempfile
import os

# é¡µé¢åŸºç¡€è®¾ç½®
st.set_page_config(page_title="å•è¯è§†é¢‘ç”Ÿæˆå™¨", layout="wide")
st.title("ğŸ¬ æ¯æ—¥å•è¯è§†é¢‘ç”Ÿæˆå™¨")
st.markdown("ä¸Šä¼ ç´ æ -> è¾“å…¥å•è¯ -> ç”Ÿæˆè§†é¢‘ã€‚")

# ================== ä¾§è¾¹æ ï¼šç´ æé…ç½® ==================
st.sidebar.header("1. ä¸Šä¼ å¿…è¦ç´ æ")
st.sidebar.info("ğŸ’¡ äº‘ç«¯æœåŠ¡å™¨æ²¡æœ‰ä¸­æ–‡å­—ä½“ï¼Œè¯·åŠ¡å¿…ä¸Šä¼ å­—ä½“æ–‡ä»¶ï¼")

# 1. ä¸Šä¼ èƒŒæ™¯å›¾
bg_file = st.sidebar.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ (9:16ç«–å±)", type=["jpg", "png", "jpeg"])
# 2. ä¸Šä¼ å­—ä½“
font_file = st.sidebar.file_uploader("ä¸Šä¼ å­—ä½“æ–‡ä»¶ (.ttf/.ttc)", type=["ttf", "ttc"])
# 3. ä¸Šä¼ éŸ³æ•ˆ
tick_file = st.sidebar.file_uploader("ä¸Šä¼ å€’è®¡æ—¶éŸ³æ•ˆ (.mp3, å¯é€‰)", type=["mp3", "wav"])

# ================== ä¸»ç•Œé¢ï¼šå†…å®¹è¾“å…¥ ==================
st.header("2. è¾“å…¥å•è¯ä¿¡æ¯")
col1, col2 = st.columns(2)

with col1:
    word = st.text_input("å•è¯ (Word)", value="Ambition")
    ipa = st.text_input("éŸ³æ ‡ (IPA)", value="/Ã¦mËˆbÉªÊƒn/")
    meaning = st.text_input("ä¸­æ–‡é‡Šä¹‰", value="n. é‡å¿ƒï¼›é›„å¿ƒï¼›æŠ±è´Ÿ")

with col2:
    sentence = st.text_area("è‹±æ–‡ä¾‹å¥", value="Her ambition was to become a pilot.")
    translation = st.text_input("ä¾‹å¥ç¿»è¯‘", value="å¥¹çš„æŠ±è´Ÿæ˜¯æˆä¸ºä¸€åé£è¡Œå‘˜ã€‚")

# ================== æ ¸å¿ƒé€»è¾‘å‡½æ•° ==================

async def generate_tts(text, voice, output_file):
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_file)

def process_video(bg_path, font_path, tick_path, data):
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹
    temp_dir = tempfile.mkdtemp()
    audio_word_path = os.path.join(temp_dir, "word.mp3")
    audio_full_path = os.path.join(temp_dir, "full.mp3")
    output_video_path = os.path.join(temp_dir, "output.mp4")

    # 1. ç”Ÿæˆè¯­éŸ³
    # å•è¯éƒ¨åˆ† (è‹±æ–‡ç”·å£°)
    asyncio.run(generate_tts(data['word'], "en-US-ChristopherNeural", audio_word_path))
    
    # å®Œæ•´éƒ¨åˆ† (ä¸ºäº†ä¸­æ–‡è‡ªç„¶ï¼Œè¿™é‡Œä½¿ç”¨ä¸­æ–‡è¯­éŸ³åŒ…è¯»å…¨æ–‡ï¼Œä½ å¯ä»¥æ ¹æ®å–œå¥½è°ƒæ•´)
    full_text = f"{data['word']}... {data['meaning']}... {data['sentence']}"
    asyncio.run(generate_tts(full_text, "zh-CN-YunxiNeural", audio_full_path))

    # 2. è½½å…¥ç´ æ
    # èƒŒæ™¯
    if bg_path:
        bg_clip = ImageClip(bg_path).resize((1080, 1920))
    else:
        bg_clip = ColorClip(size=(1080, 1920), color=(0,0,0)) # é»˜è®¤é»‘åº•

    # å­—ä½“ (å¦‚æœç”¨æˆ·æ²¡ä¼ ï¼Œå°è¯•ç”¨ Arialï¼Œä½†åœ¨ Linux ä¸Šä¸­æ–‡å¯èƒ½ä¼šä¹±ç )
    used_font = font_path if font_path else "Arial"

    # éŸ³é¢‘
    audio_word_clip = AudioFileClip(audio_word_path)
    audio_full_clip = AudioFileClip(audio_full_path)
    
    tick_sfx = None
    if tick_path:
        try:
            tick_sfx = AudioFileClip(tick_path).subclip(0, 3).volumex(0.3)
        except:
            pass

    # --- é˜¶æ®µ 1: æé—® (3ç§’+å•è¯æ—¶é•¿) ---
    phase1_duration = max(3.5, audio_word_clip.duration + 2.5)
    
    # åˆ¶ä½œæ–‡å­—å›¾ç‰‡
    txt_word_huge = TextClip(data['word'], fontsize=150, color='white', font=used_font, method='label')
    txt_word_huge = txt_word_huge.set_position('center').set_duration(phase1_duration)
    
    # æ··åˆéŸ³é¢‘
    audio_track_1 = audio_word_clip
    if tick_sfx:
        # å•è¯è¯»å®Œæˆ–0.5ç§’åå¼€å§‹å€’è®¡æ—¶
        audio_track_1 = CompositeAudioClip([audio_word_clip, tick_sfx.set_start(0.5)])
    
    clip_phase_1 = CompositeVideoClip([bg_clip.set_duration(phase1_duration), txt_word_huge])
    clip_phase_1 = clip_phase_1.set_audio(audio_track_1.set_duration(phase1_duration))

    # --- é˜¶æ®µ 2: æ­ç¤º (é‡Šä¹‰æ—¶é•¿) ---
    phase2_duration = audio_full_clip.duration + 1.0
    
    txt_word_top = TextClip(data['word'] + "\n" + data['ipa'], fontsize=100, color='yellow', font=used_font, method='label')
    txt_word_top = txt_word_top.set_position(('center', 400)).set_duration(phase2_duration)
    
    txt_meaning = TextClip(data['meaning'], fontsize=70, color='white', font=used_font, method='caption', size=(900, None))
    txt_meaning = txt_meaning.set_position(('center', 'center')).set_duration(phase2_duration)
    
    ex_text = f"{data['sentence']}\n{data['translation']}"
    txt_example = TextClip(ex_text, fontsize=50, color='lightgrey', font=used_font, method='caption', size=(900, None))
    txt_example = txt_example.set_position(('center', 1300)).set_duration(phase2_duration)

    clip_phase_2 = CompositeVideoClip([
        bg_clip.set_duration(phase2_duration),
        txt_word_top,
        txt_meaning,
        txt_example
    ])
    clip_phase_2 = clip_phase_2.set_audio(audio_full_clip)

    # --- åˆæˆæœ€ç»ˆè§†é¢‘ ---
    final_video = concatenate_videoclips([clip_phase_1, clip_phase_2])
    final_video.write_videofile(output_video_path, fps=24, codec='libx264', audio_codec='aac')
    
    return output_video_path

# ================== æ‰§è¡ŒæŒ‰é’® ==================
st.divider()
if st.button("ğŸš€ ç”Ÿæˆè§†é¢‘", type="primary"):
    if not font_file:
        st.error("âŒ é”™è¯¯ï¼šè¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ å­—ä½“æ–‡ä»¶ï¼ˆ.ttf æˆ– .ttcï¼‰ï¼Œå¦åˆ™æ— æ³•ç”Ÿæˆæ–‡å­—ã€‚")
    else:
        with st.spinner("æ­£åœ¨åˆæˆè§†é¢‘... è¯·è€å¿ƒç­‰å¾… 15-30 ç§’..."):
            try:
                # å¤„ç†ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶
                t_bg = None
                if bg_file:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as f:
                        f.write(bg_file.read())
                        t_bg = f.name
                
                t_font = None
                if font_file:
                    suffix = ".ttc" if font_file.name.endswith(".ttc") else ".ttf"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as f:
                        f.write(font_file.read())
                        t_font = f.name
                
                t_tick = None
                if tick_file:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                        f.write(tick_file.read())
                        t_tick = f.name

                data = {
                    "word": word, "ipa": ipa, "meaning": meaning, 
                    "sentence": sentence, "translation": translation
                }
                
                video_path = process_video(t_bg, t_font, t_tick, data)
                
                st.success("âœ… è§†é¢‘åˆ¶ä½œå®Œæˆï¼")
                st.video(video_path)
                
                with open(video_path, "rb") as file:
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½è§†é¢‘",
                        data=file,
                        file_name=f"{word}_vocab.mp4",
                        mime="video/mp4"
                    )
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

import streamlit as st
import asyncio
import edge_tts
from moviepy.editor import *
import tempfile
import os

# ================= é…ç½®åŒºåŸŸ =================
# è¿™é‡Œçš„å­—ä½“æ–‡ä»¶åå¿…é¡»å’Œä½ ä¸Šä¼ åˆ° GitHub (æˆ–æœ¬åœ°æ–‡ä»¶å¤¹) çš„åå­—å®Œå…¨ä¸€è‡´
DEFAULT_FONT = "font.ttf" 

# æ›´ç¨³å®šçš„è¯­éŸ³è§’è‰²é…ç½®
VOICE_EN = "en-US-AriaNeural"      # å¾®è½¯æœ€ç¨³çš„è‹±æ–‡å¥³å£°
VOICE_ZH = "zh-CN-XiaoxiaoNeural"  # å¾®è½¯æœ€ç¨³çš„ä¸­æ–‡å¥³å£°

# ================= é¡µé¢è®¾ç½® =================
st.set_page_config(page_title="å•è¯è§†é¢‘ç”Ÿæˆå™¨", layout="wide")
st.title("ğŸ¬ æ¯æ—¥å•è¯è§†é¢‘ç”Ÿæˆå™¨ (ä¿®å¤ç‰ˆ)")

# ================== ä¾§è¾¹æ ï¼šç´ æé…ç½® ==================
st.sidebar.header("âš™ï¸ ç´ æé…ç½®")

# æ£€æŸ¥å­—ä½“æ˜¯å¦å­˜åœ¨
if not os.path.exists(DEFAULT_FONT):
    st.sidebar.error(f"âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° {DEFAULT_FONT}ï¼è¯·ç¡®ä¿å­—ä½“æ–‡ä»¶å·²ä¸Šä¼ ä¸”é‡å‘½åæ­£ç¡®ã€‚")
    current_font = "Arial" 
else:
    st.sidebar.success(f"âœ… å·²åŠ è½½å­—ä½“: {DEFAULT_FONT}")
    current_font = DEFAULT_FONT

bg_file = st.sidebar.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ (9:16ç«–å±, ä¸ä¼ åˆ™ç”¨é»‘åº•)", type=["jpg", "png", "jpeg"])
tick_file = st.sidebar.file_uploader("ä¸Šä¼ å€’è®¡æ—¶éŸ³æ•ˆ (å¯é€‰)", type=["mp3", "wav"])

# ================== ä¸»ç•Œé¢ï¼šå†…å®¹è¾“å…¥ ==================
st.divider()
col1, col2 = st.columns(2)

with col1:
    word = st.text_input("å•è¯ (Word)", value="Ambition")
    ipa = st.text_input("éŸ³æ ‡ (IPA)", value="/Ã¦mËˆbÉªÊƒn/")
    meaning = st.text_input("ä¸­æ–‡é‡Šä¹‰", value="n. é‡å¿ƒï¼›é›„å¿ƒï¼›æŠ±è´Ÿ")

with col2:
    sentence = st.text_area("è‹±æ–‡ä¾‹å¥", value="Her ambition was to become a pilot.")
    translation = st.text_input("ä¾‹å¥ç¿»è¯‘", value="å¥¹çš„æŠ±è´Ÿæ˜¯æˆä¸ºä¸€åé£è¡Œå‘˜ã€‚")

# ================== æ ¸å¿ƒé€»è¾‘å‡½æ•° (ä¿®å¤ç‰ˆ) ==================

async def generate_tts_safe(text, voice, output_file):
    """
    å¸¦é‡è¯•æœºåˆ¶çš„è¯­éŸ³ç”Ÿæˆå‡½æ•°
    """
    if not text or len(text.strip()) == 0:
        return # æ–‡æœ¬ä¸ºç©ºä¸å¤„ç†
        
    try:
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(output_file)
    except Exception as e:
        # å¦‚æœé¦–é€‰å£°éŸ³å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨å£°éŸ³ (Guy æ˜¯ç”·å£°ï¼ŒYunxi æ˜¯ç”·å£°)
        print(f"é¦–é€‰è¯­éŸ³å¤±è´¥: {e}ï¼Œå°è¯•å¤‡ç”¨è¯­éŸ³...")
        try:
            backup_voice = "en-US-GuyNeural" if "en-US" in voice else "zh-CN-YunxiNeural"
            communicate = edge_tts.Communicate(text, backup_voice)
            await communicate.save(output_file)
        except Exception as e2:
            raise Exception(f"è¯­éŸ³ç”Ÿæˆå½»åº•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚é”™è¯¯ä¿¡æ¯: {str(e2)}")

def process_video(bg_path, font_path, tick_path, data):
    temp_dir = tempfile.mkdtemp()
    audio_word_path = os.path.join(temp_dir, "word.mp3")
    audio_full_path = os.path.join(temp_dir, "full.mp3")
    output_video_path = os.path.join(temp_dir, "output.mp4")

    # 1. ç”Ÿæˆè¯­éŸ³ (ä½¿ç”¨ä¿®å¤ç‰ˆå‡½æ•°)
    try:
        asyncio.run(generate_tts_safe(data['word'], VOICE_EN, audio_word_path))
        
        full_text = f"{data['word']}... {data['meaning']}... {data['sentence']}"
        asyncio.run(generate_tts_safe(full_text, VOICE_ZH, audio_full_path))
    except Exception as e:
        st.error(f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼š{e}")
        return None

    # 2. è½½å…¥ç´ æ
    if bg_path:
        bg_clip = ImageClip(bg_path).resize((1080, 1920))
    else:
        bg_clip = ColorClip(size=(1080, 1920), color=(0,0,0))

    audio_word_clip = AudioFileClip(audio_word_path)
    audio_full_clip = AudioFileClip(audio_full_path)
    
    tick_sfx = None
    if tick_path:
        try:
            tick_sfx = AudioFileClip(tick_path).subclip(0, 3).volumex(0.3)
        except:
            pass

    # --- é˜¶æ®µ 1 ---
    # ç¡®ä¿æ—¶é•¿è‡³å°‘ä¸º3ç§’ï¼Œå¦‚æœè¯­éŸ³æ›´é•¿åˆ™è·Ÿéšè¯­éŸ³
    phase1_duration = max(3.5, audio_word_clip.duration + 2.5)
    
    txt_word_huge = TextClip(data['word'], fontsize=150, color='white', font=font_path, method='label')
    txt_word_huge = txt_word_huge.set_position('center').set_duration(phase1_duration)
    
    audio_track_1 = audio_word_clip
    if tick_sfx:
        # å•è¯è¯»å®Œæˆ–0.5ç§’åå¼€å§‹å€’è®¡æ—¶
        audio_track_1 = CompositeAudioClip([audio_word_clip, tick_sfx.set_start(0.5)])
    
    clip_phase_1 = CompositeVideoClip([bg_clip.set_duration(phase1_duration), txt_word_huge])
    clip_phase_1 = clip_phase_1.set_audio(audio_track_1.set_duration(phase1_duration))

    # --- é˜¶æ®µ 2 ---
    phase2_duration = audio_full_clip.duration + 1.0
    
    txt_word_top = TextClip(data['word'] + "\n" + data['ipa'], fontsize=100, color='yellow', font=font

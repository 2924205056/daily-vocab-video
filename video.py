import streamlit as st
import asyncio
import edge_tts
from moviepy.editor import *
import tempfile
import os
import platform

# ================= é…ç½®åŒºåŸŸ =================
DEFAULT_FONT = "font.ttf" 

# å¾®è½¯è¯­éŸ³é…ç½® (äº‘ç«¯è¿è¡Œæ—¶ç”¨)
VOICE_EN = "en-US-ChristopherNeural"
VOICE_ZH = "zh-CN-XiaoxiaoNeural"

# ================= é¡µé¢è®¾ç½® =================
st.set_page_config(page_title="å•è¯è§†é¢‘ç”Ÿæˆå™¨", layout="wide")
st.title("ğŸ¬ æ¯æ—¥å•è¯è§†é¢‘ç”Ÿæˆå™¨ (Macæœ¬åœ° + äº‘ç«¯åŒæ¨¡ç‰ˆ)")

# ================== ä¾§è¾¹æ  ==================
st.sidebar.header("âš™ï¸ ç´ æé…ç½®")
if not os.path.exists(DEFAULT_FONT):
    st.sidebar.error(f"âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° {DEFAULT_FONT}ï¼")
    current_font = "Arial" 
else:
    st.sidebar.success(f"âœ… å·²åŠ è½½å­—ä½“: {DEFAULT_FONT}")
    current_font = DEFAULT_FONT

bg_file = st.sidebar.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾", type=["jpg", "png", "jpeg"])
tick_file = st.sidebar.file_uploader("ä¸Šä¼ å€’è®¡æ—¶éŸ³æ•ˆ", type=["mp3", "wav"])

st.divider()
col1, col2 = st.columns(2)
with col1:
    word = st.text_input("å•è¯", value="Ambition")
    ipa = st.text_input("éŸ³æ ‡", value="/Ã¦mËˆbÉªÊƒn/")
    meaning = st.text_input("ä¸­æ–‡é‡Šä¹‰", value="n. é‡å¿ƒï¼›é›„å¿ƒï¼›æŠ±è´Ÿ")
with col2:
    sentence = st.text_area("è‹±æ–‡ä¾‹å¥", value="Her ambition was to become a pilot.")
    translation = st.text_input("ä¾‹å¥ç¿»è¯‘", value="å¥¹çš„æŠ±è´Ÿæ˜¯æˆä¸ºä¸€åé£è¡Œå‘˜ã€‚")

# ================== æ ¸å¿ƒè¯­éŸ³å‡½æ•° (å…³é”®ä¿®æ”¹) ==================

def use_mac_tts(text, lang, filename):
    """
    ä½¿ç”¨ Mac è‡ªå¸¦çš„ 'say' å‘½ä»¤ç”Ÿæˆè¯­éŸ³ï¼Œä¸éœ€è¦è”ç½‘
    """
    # è‹±æ–‡ç”¨ Samantha (Siriå£°çº¿), ä¸­æ–‡ç”¨ Ting-Ting
    voice = "Samantha" if lang == "en" else "Ting-Ting"
    
    # Mac çš„ say å‘½ä»¤ç”Ÿæˆçš„æ˜¯ aiff æ ¼å¼ï¼Œffmpeg (moviepy) å¯ä»¥ç›´æ¥è¯»å–
    # è¿™é‡Œçš„ -o filename æ˜¯è¾“å‡ºè·¯å¾„
    cmd = f'say -v {voice} -o "{filename}" "{text}"'
    print(f"æ­£åœ¨ä½¿ç”¨ Mac æœ¬åœ°è¯­éŸ³: {cmd}")
    os.system(cmd)

async def generate_tts_smart(text, voice, output_file, lang_code="en"):
    """
    æ™ºèƒ½è¯­éŸ³ç”Ÿæˆï¼šä¼˜å…ˆå°è¯•å¾®è½¯ Edge-TTSï¼Œå¤±è´¥åˆ™åˆ‡æ¢ Mac æœ¬åœ°
    """
    if not text: return

    # 1. å°è¯•å¾®è½¯ Edge-TTS (ç½‘ç»œå¥½æ—¶éŸ³è´¨æœ€å¥½)
    try:
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(output_file)
    except Exception as e:
        print(f"å¾®è½¯è¯­éŸ³è¿æ¥å¤±è´¥ ({e})ï¼Œåˆ‡æ¢ Mac æœ¬åœ°è¯­éŸ³...")
        
        # 2. å¦‚æœå¤±è´¥ï¼Œæ£€æŸ¥æ˜¯ä¸æ˜¯åœ¨ Mac ä¸Šï¼Œæ˜¯çš„è¯ç”¨æœ¬åœ°è¯­éŸ³
        if platform.system() == 'Darwin':
            # åˆ é™¤å¯èƒ½å­˜åœ¨çš„ç©ºæ–‡ä»¶
            if os.path.exists(output_file): os.remove(output_file)
            # è°ƒç”¨ Mac ç³»ç»Ÿè¯­éŸ³
            use_mac_tts(text, lang_code, output_file)
        else:
            st.error("âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼šç½‘ç»œä¸é€šä¸”é Mac ç³»ç»Ÿã€‚è¯·éƒ¨ç½²åˆ°äº‘ç«¯ä½¿ç”¨ã€‚")
            raise e

def process_video(bg_path, font_path, tick_path, data):
    temp_dir = tempfile.mkdtemp()
    audio_word_path = os.path.join(temp_dir, "word.aiff") # Mac say é»˜è®¤æ ¼å¼å…¼å®¹æ€§æ›´å¥½
    audio_full_path = os.path.join(temp_dir, "full.aiff")
    output_video_path = os.path.join(temp_dir, "output.mp4")

    # 1. ç”Ÿæˆè¯­éŸ³ (æ™ºèƒ½æ¨¡å¼)
    try:
        # å•è¯ (è‹±æ–‡)
        asyncio.run(generate_tts_smart(data['word'], VOICE_EN, audio_word_path, "en"))
        
        # å¥å­ (ä¸­æ–‡+è‹±æ–‡)
        full_text = f"{data['word']}... {data['meaning']}... {data['sentence']}"
        asyncio.run(generate_tts_smart(full_text, VOICE_ZH, audio_full_path, "zh"))
    except:
        return None

    # 2. è½½å…¥ç´ æ
    if bg_path:
        bg_clip = ImageClip(bg_path).resize((1080, 1920))
    else:
        bg_clip = ColorClip(size=(1080, 1920), color=(0,0,0))

    # è¯»å–éŸ³é¢‘ (MoviePy ä¼šè‡ªåŠ¨å¤„ç† aiff/mp3)
    try:
        audio_word_clip = AudioFileClip(audio_word_path)
        audio_full_clip = AudioFileClip(audio_full_path)
    except OSError:
        st.error("âŒ éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼Œå¯èƒ½æ˜¯ Mac æ²¡æœ‰å®‰è£…ä¸­æ–‡è¯­éŸ³åŒ… (ç³»ç»Ÿåå¥½è®¾ç½®->è¾…åŠ©åŠŸèƒ½->æœ—è¯»å†…å®¹->ç³»ç»Ÿå£°éŸ³ é€‰å©·å©·)")
        return None
    
    tick_sfx = None
    if tick_path:
        try:
            tick_sfx = AudioFileClip(tick_path).subclip(0, 3).volumex(0.3)
        except:
            pass

    # --- é˜¶æ®µ 1 ---
    phase1_duration = max(3.5, audio_word_clip.duration + 2.5)
    
    txt_word_huge = TextClip(data['word'], fontsize=150, color='white', font=font_path, method='label')
    txt_word_huge = txt_word_huge.set_position('center').set_duration(phase1_duration)
    
    audio_track_1 = audio_word_clip
    if tick_sfx:
        audio_track_1 = CompositeAudioClip([audio_word_clip, tick_sfx.set_start(0.5)])
    
    clip_phase_1 = CompositeVideoClip([bg_clip.set_duration(phase1_duration), txt_word_huge])
    clip_phase_1 = clip_phase_1.set_audio(audio_track_1.set_duration(phase1_duration))

    # --- é˜¶æ®µ 2 ---
    phase2_duration = audio_full_clip.duration + 1.0
    
    txt_word_top = TextClip(data['word'] + "\n" + data['ipa'], fontsize=100, color='yellow', font=font_path, method='label')
    txt_word_top = txt_word_top.set_position(('center', 400)).set_duration(phase2_duration)
    
    txt_meaning = TextClip(data['meaning'], fontsize=70, color='white', font=font_path, method='caption', size=(900, None))
    txt_meaning = txt_meaning.set_position(('center', 'center')).set_duration(phase2_duration)
    
    ex_text = f"{data['sentence']}\n{data['translation']}"
    txt_example = TextClip(ex_text, fontsize=50, color='lightgrey', font=font_path, method='caption', size=(900, None))
    txt_example = txt_example.set_position(('center', 1300)).set_duration(phase2_duration)

    clip_phase_2 = CompositeVideoClip([
        bg_clip.set_duration(phase2_duration),
        txt_word_top,
        txt_meaning,
        txt_example
    ])
    clip_phase_2 = clip_phase_2.set_audio(audio_full_clip)

    final_video = concatenate_videoclips([clip_phase_1, clip_phase_2])
    final_video.write_videofile(output_video_path, fps=24, codec='libx264', audio_codec='aac')
    return output_video_path

# ================== æ‰§è¡Œ ==================
if st.button("ğŸš€ ç”Ÿæˆè§†é¢‘ (Macå…¼å®¹ç‰ˆ)", type="primary"):
    with st.spinner("æ­£åœ¨åˆæˆ... (å¦‚è”ç½‘å¤±è´¥ä¼šè‡ªåŠ¨åˆ‡æ¢Macè¯­éŸ³)"):
        try:
            t_bg = None
            if bg_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as f:
                    f.write(bg_file.read())
                    t_bg = f.name
            
            t_tick = None
            if tick_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                    f.write(tick_file.read())
                    t_tick = f.name

            data = {"word": word, "ipa": ipa, "meaning": meaning, "sentence": sentence, "translation": translation}
            
            video_path = process_video(t_bg, current_font, t_tick, data)
            
            if video_path:
                st.success("âœ… å®Œæˆï¼")
                st.video(video_path)
        except Exception as e:
            st
